{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/christianwarmuth/openhpi-kipraxis/blob/main/Woche%201/1_8_3_Kalifornien_Hauspreise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb706ac5"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os # u.a. zur Entwicklugn plattformübergreifender Systempfade\n",
    "import pandas as pd # Datenmanagement\n",
    "import numpy as np # Hilfsfunktionen für mathematische Operationen\n",
    "\n",
    "# Datenvisualisierung\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split # Datensplits\n",
    "from sklearn.linear_model import LinearRegression # Machine Learning\n",
    "from sklearn import metrics # Modellevaluierung\n",
    "\n",
    "## eigene Funktionen\n",
    "def filter_df_by_proximity(df, proximity):\n",
    "    return df.loc[df[\"ocean_proximity\"] == proximity]\n",
    "\n",
    "def engineer_features(df):\n",
    "    df[\"ratio_bedrooms\"] = df[\"total_bedrooms\"] / df[\"total_rooms\"]\n",
    "    df[\"people_per_household\"] = df[\"population\"] / df[\"households\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b8b327a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "import requests\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.getcwd()\n",
    "CALIFORNIA_URL = \"https://raw.githubusercontent.com/christianwarmuth/openhpi-kipraxis/main/images/california.png\"\n",
    "CALIFORNIA_PATH = \"california.png\"\n",
    "FILE_PATH = \"housing.csv\"\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "response = requests.get(CALIFORNIA_URL, stream=True)\n",
    "with open(CALIFORNIA_PATH, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "del response\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()\n",
    "\n",
    "df = pd.read_csv(FILE_PATH) # Wir lesen die Datei housing.csv ein\n",
    "\n",
    "df = df.dropna() # löscht alle Zeile mit fehlenden Attributen\n",
    "df = df.reset_index(drop=True) # zählt unsere Daten neu durch\n",
    "\n",
    "description = df.describe()\n",
    "\n",
    "bins = [0] + list(description[\"median_house_value\"][\n",
    "    [\"25%\", \"50%\", \"75%\"]\n",
    "].astype(int)) + [np.inf]\n",
    "\n",
    "df[\"house_cat\"] = pd.cut(\n",
    "    df[\"median_house_value\"],\n",
    "    bins=bins,\n",
    "    labels=[\"0 - 25%\", \"25 - 50%\", \"50 - 75%\", \"75 - 100%\"]\n",
    ")\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "for train_index, test_index in split.split(df, df[\"house_cat\"]):\n",
    "    df_train = df.loc[train_index]\n",
    "    df_test = df.loc[test_index]\n",
    "    \n",
    "df_train = df_train.drop(\"house_cat\", axis=1)\n",
    "df_test = df_test.drop(\"house_cat\", axis=1)\n",
    "\n",
    "df_train = df_train.drop(filter_df_by_proximity(df_train, \"ISLAND\").index)\n",
    "df_test = df_test.drop(filter_df_by_proximity(df_test, \"ISLAND\").index)\n",
    "\n",
    "df_train = engineer_features(df_train)\n",
    "df_test = engineer_features(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e67c8da4"
   },
   "source": [
    "# 1.8 Hauspreise in Kalifornien\n",
    "\n",
    "<img width=70% src=\"https://raw.githubusercontent.com/christianwarmuth/openhpi-kipraxis/main/images/cover_housing.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30b8cc15"
   },
   "source": [
    "### Rohdaten in KI-Format bringen\n",
    "\n",
    "Wir wollen nun unser erstes Machine Learning-Modell im Supervised Learning-Stil implementieren und trainieren. Schauen wir nochmal auf unsere Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cb06e59"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7900757"
   },
   "source": [
    "Wir haben mit `ocean_proximity` noch ein kategoriales Attribut. Die meisten ML-Algorithmen können jedoch nur numerischen Input verarbeiten; wir müssen diese also noch transformieren. Die einfachste Wahl ist hier eine One-Hot Transformation. Auch hier hilft uns `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee3a1e3b"
   },
   "outputs": [],
   "source": [
    "df_train_ml = pd.get_dummies(df_train) # One-Hot Encoding\n",
    "df_test_ml = pd.get_dummies(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8c5dc1f"
   },
   "source": [
    "Schauen wir uns die Daten erneut an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79de196e"
   },
   "outputs": [],
   "source": [
    "df_train_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a369f1b1"
   },
   "source": [
    "Wir haben nun nur noch numerische Daten in unseren Attributen. Es kann losgehen! :)\n",
    "Wir werden unsere Daten nun in die Eingabenmatrix `X` und den Vektor `y` transformieren, aus denen unser Modell lernen wird. Wir bauen uns dafür eine Hilfsfunktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aa6ba33"
   },
   "outputs": [],
   "source": [
    "def get_features_and_targets(df):\n",
    "    X = df.drop([\"median_house_value\"], axis=1).values\n",
    "    y = np.stack(df[\"median_house_value\"])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "601a13e1"
   },
   "source": [
    "Anschließend wenden wir unsere Funktion auf unsere Daten an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e2fee30"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_features_and_targets(df_train_ml)\n",
    "X_test, y_test = get_features_and_targets(df_test_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dcec1af"
   },
   "source": [
    "### KI-Implementierung und Training\n",
    "\n",
    "Nun kommt der Part, auf den wir bisher gewartet haben; wir bauen und trainieren unser erstes KI-Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1966de3"
   },
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0b7ae1b"
   },
   "source": [
    "... das war tatsächlich schon die Implementierung + Training!\n",
    "\n",
    "\n",
    "Zugegeben, eine lineare Regression gilt noch nicht als hochmoderner KI-Algorithmus - und selbst beim Training dieser Regression können wir noch einige Optimierungen durch Trainingskonfigurationen vornehmen. \n",
    "\n",
    "Nichtsdestotrotz ist dies unser erstes Modell, welches rein auf Basis von Daten in der Lage ist, zu lernen, um Progonsen zu erstellen. Mit `scikit-learn` gibt es eine hervorragende Python-Bibliothek, die eine Vielzahl von KI-Modellen bereitstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2h8ill8noXP"
   },
   "outputs": [],
   "source": [
    "from skl2onnx import to_onnx\n",
    "\n",
    "onx = to_onnx(clr, X[:1])\n",
    "with open(\"house_prices.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1.9_3 Kalifornien Hauspreise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
